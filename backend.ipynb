{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II2tkRSkVEwv",
        "outputId": "33f3e231-fd6f-4aef-94e5-8a19293421c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install openai tqdm numpy tiktoken pinecone fastapi uvicorn pyngrok pydantic -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfg2PLWkabkF"
      },
      "source": [
        "####**IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81j50lNhaaiz"
      },
      "outputs": [],
      "source": [
        "import os, textwrap, math, openai, uvicorn\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from fastapi import FastAPI\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import FileResponse\n",
        "from pydantic import BaseModel\n",
        "from pyngrok import conf, ngrok\n",
        "from pathlib import Path\n",
        "import multiprocessing as mp\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWvTyDbMTgdL"
      },
      "source": [
        "####**API KEYS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlB9sY9JS4vy"
      },
      "outputs": [],
      "source": [
        "# Pinecone (v3) initialization\n",
        "pc = Pinecone(api_key=userdata.get(\"PINECONE_API_KEY\"))\n",
        "\n",
        "index_name = \"java-embeddings\"\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=1536,  # for text-embedding-3-small\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Choose models\n",
        "CHAT_MODEL   = \"gpt-4o\"\n",
        "EMBED_MODEL  = \"text-embedding-3-small\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AIndY16TZ6X"
      },
      "source": [
        "####**HELPER FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "RIUwCdkXTYl_"
      },
      "outputs": [],
      "source": [
        "def top_k_chunks(query, k=3):\n",
        "    q_emb = openai.embeddings.create(model=EMBED_MODEL, input=query).data[0].embedding\n",
        "    res = index.query(vector=q_emb, top_k=k, include_metadata=True)\n",
        "    return [(match.metadata[\"text\"], match.score) for match in res.matches]\n",
        "\n",
        "def chat(messages, temp=0.0):\n",
        "    resp = openai.chat.completions.create(\n",
        "        model=CHAT_MODEL, messages=messages, temperature=temp\n",
        "    )\n",
        "    msg = resp.choices[0].message.content.strip()\n",
        "    usage = resp.usage\n",
        "    return msg, usage.prompt_tokens, usage.completion_tokens\n",
        "\n",
        "def answer_kb_only(question, k=5):\n",
        "    hits = top_k_chunks(question, k)\n",
        "    return \"\\n\\n-----------------\\n\".join(f\"[Score {score:.3f}]\\n{txt}\" for txt, score in hits), 0, 0\n",
        "\n",
        "def answer_rag(question, k=5):\n",
        "    context = \"\\n\".join(\"â€¢ \" + txt.replace(\"\\n\", \" \") for txt, _ in top_k_chunks(question, k))\n",
        "    sys_prompt = (\n",
        "        \"You are an expert assistant. Use ONLY the facts below (plus your own language knowledge) to answer:\\n\\n\"\n",
        "        + context\n",
        "    )\n",
        "    msgs = [\n",
        "        {\"role\": \"system\", \"content\": sys_prompt},\n",
        "        {\"role\": \"user\",   \"content\": question}\n",
        "    ]\n",
        "    return chat(msgs)\n",
        "\n",
        "def answer_no_context(question):\n",
        "    msgs = [{\"role\": \"user\", \"content\": question}]\n",
        "    return chat(msgs)\n",
        "\n",
        "MODES = {\n",
        "    \"1\": (\"KB-only (retrieved snippets)\",    answer_kb_only),\n",
        "    \"2\": (\"RAG (top-k chunks only)\",          answer_rag),\n",
        "    \"3\": (\"No KB (just question to model)\",   answer_no_context),\n",
        "}\n",
        "\n",
        "#mode = input(\"Choose mode (1-3): \").strip()\n",
        "#title, fn = MODES[2]\n",
        "#print(f\"\\n--- {title} ---\\n\")\n",
        "#reply, in_tok, out_tok = fn(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bTeOS0Oa2K2"
      },
      "source": [
        "####**SETUP SERVER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ponjoSkJUPzo",
        "outputId": "715fefde-6720-40b6-fd6c-fa5b6601a7a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "t=2025-06-12T16:24:46-0400 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "t=2025-06-12T16:24:46-0400 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "t=2025-06-12T16:24:46-0400 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n",
            "t=2025-06-12T16:24:46-0400 lvl=crit msg=\"command failed\" err=\"authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n\"\n"
          ]
        },
        {
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mPyngrokNgrokError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     39\u001b[39m ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n\u001b[32m     40\u001b[39m ngrok.kill()  \u001b[38;5;66;03m# Clean any previous tunnels\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m public_url = \u001b[43mngrok\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddr\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m8000\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbind_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPublic URL:\u001b[39m\u001b[33m\"\u001b[39m, public_url.public_url)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Start API in a separate process\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\benki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyngrok\\ngrok.py:385\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(addr, proto, name, pyngrok_config, **options)\u001b[39m\n\u001b[32m    381\u001b[39m _upgrade_legacy_params(pyngrok_config, options)\n\u001b[32m    383\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOpening tunnel named: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m api_url = \u001b[43mget_ngrok_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyngrok_config\u001b[49m\u001b[43m)\u001b[49m.api_url\n\u001b[32m    387\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCreating tunnel with options: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    389\u001b[39m tunnel = NgrokTunnel(api_request(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/api/tunnels\u001b[39m\u001b[33m\"\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m, data=options,\n\u001b[32m    390\u001b[39m                                  timeout=pyngrok_config.request_timeout),\n\u001b[32m    391\u001b[39m                      pyngrok_config, api_url)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\benki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyngrok\\ngrok.py:203\u001b[39m, in \u001b[36mget_ngrok_process\u001b[39m\u001b[34m(pyngrok_config)\u001b[39m\n\u001b[32m    199\u001b[39m     pyngrok_config = conf.get_default()\n\u001b[32m    201\u001b[39m install_ngrok(pyngrok_config)\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyngrok_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\benki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyngrok\\process.py:271\u001b[39m, in \u001b[36mget_process\u001b[39m\u001b[34m(pyngrok_config)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_process_running(pyngrok_config.ngrok_path):\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _current_processes[pyngrok_config.ngrok_path]\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_start_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyngrok_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\benki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyngrok\\process.py:447\u001b[39m, in \u001b[36m_start_process\u001b[39m\u001b[34m(pyngrok_config)\u001b[39m\n\u001b[32m    444\u001b[39m kill_process(pyngrok_config.ngrok_path)\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ngrok_process.startup_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PyngrokNgrokError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe ngrok process errored on start: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mngrok_process.startup_error\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    448\u001b[39m                             ngrok_process.logs,\n\u001b[32m    449\u001b[39m                             ngrok_process.startup_error)\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    451\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PyngrokNgrokError(\u001b[33m\"\u001b[39m\u001b[33mThe ngrok process was unable to start.\u001b[39m\u001b[33m\"\u001b[39m, ngrok_process.logs)\n",
            "\u001b[31mPyngrokNgrokError\u001b[39m: The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\\nYou can view your current agent sessions in the dashboard:\\nhttps://dashboard.ngrok.com/agents\\r\\n\\r\\nERR_NGROK_108\\r\\n."
          ]
        }
      ],
      "source": [
        "app = FastAPI(title=\"AP CS Test Teacher\")\n",
        "\n",
        "app.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\n",
        "\n",
        "@app.get(\"/\")\n",
        "def root():\n",
        "    return FileResponse(\"static/index.html\")\n",
        "\n",
        "# Enable CORS for all origins\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],  # Allow all\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# OpenAI API key input\n",
        "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Pydantic model for the request body\n",
        "class PromptRequest(BaseModel):\n",
        "    prompt: str\n",
        "\n",
        "@app.post(\"/ask\")\n",
        "async def ask_openai(request: PromptRequest):\n",
        "  print(request.prompt)\n",
        "  answer, in_tok, out_tok = answer_rag(request.prompt)\n",
        "  print(answer)\n",
        "  return {\"response\": answer}\n",
        "\n",
        "def start_api():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# Launch with ngrok\n",
        "if __name__ == \"__main__\":\n",
        "    NGROK_AUTH_TOKEN = userdata.get(\"NGROK_AUTH_TOKEN\")\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    ngrok.kill()  # Clean any previous tunnels\n",
        "    public_url = ngrok.connect(addr=\"8000\", proto=\"http\", bind_tls=True)\n",
        "    print(\"Public URL:\", public_url.public_url)\n",
        "\n",
        "    # Start API in a separate process\n",
        "    api_proc = mp.Process(target=start_api, daemon=True)\n",
        "    api_proc.start()\n",
        "\n",
        "    try:\n",
        "        api_proc.join()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nShutting downâ€¦\")\n",
        "        api_proc.terminate()\n",
        "        ngrok.kill()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
